{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install kaggle --upgrade\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -O ./spark-3.3.1-bin-hadoop3.tgz  https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n","!tar zxvf ./spark-3.3.1-bin-hadoop3.tgz\n","!pip install findspark\n","!pip install pyspark\n","import findspark\n","import random\n","import pyspark\n","from pyspark.sql import functions as f\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/kaggle/working/spark-3.3.1-bin-hadoop3\"\n","findspark.init()\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('treatmeant').getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:02:49.744671Z","iopub.status.busy":"2023-02-15T14:02:49.744170Z","iopub.status.idle":"2023-02-15T14:02:49.752965Z","shell.execute_reply":"2023-02-15T14:02:49.751440Z","shell.execute_reply.started":"2023-02-15T14:02:49.744628Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.clustering import KMeans\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.functions import col\n","from pyspark.ml import Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:02:50.484025Z","iopub.status.busy":"2023-02-15T14:02:50.483035Z","iopub.status.idle":"2023-02-15T14:02:57.490531Z","shell.execute_reply":"2023-02-15T14:02:57.489507Z","shell.execute_reply.started":"2023-02-15T14:02:50.483946Z"},"trusted":true},"outputs":[],"source":["# Use Spark to read the training csv file.\n","data = spark.read.csv(\"/kaggle/working/df_maens.csv\", header=True)\n","cols = data.columns[2:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:02:57.493686Z","iopub.status.busy":"2023-02-15T14:02:57.492372Z","iopub.status.idle":"2023-02-15T14:02:57.788795Z","shell.execute_reply":"2023-02-15T14:02:57.787778Z","shell.execute_reply.started":"2023-02-15T14:02:57.493633Z"},"trusted":true},"outputs":[],"source":["for col_name in cols:\n","    data = data.withColumn(col_name,col(col_name).cast(\"float\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:02:58.323725Z","iopub.status.busy":"2023-02-15T14:02:58.322792Z","iopub.status.idle":"2023-02-15T14:02:58.380441Z","shell.execute_reply":"2023-02-15T14:02:58.378747Z","shell.execute_reply.started":"2023-02-15T14:02:58.323675Z"},"trusted":true},"outputs":[],"source":["assembler = VectorAssembler(inputCols=data.columns[2:], outputCol=\"features\",handleInvalid=\"keep\")\n","model = KMeans(k=2, seed=1)\n","pipeline = Pipeline(stages=[assembler, model])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:02:58.383004Z","iopub.status.busy":"2023-02-15T14:02:58.382543Z","iopub.status.idle":"2023-02-15T14:03:02.969700Z","shell.execute_reply":"2023-02-15T14:03:02.967986Z","shell.execute_reply.started":"2023-02-15T14:02:58.382969Z"},"trusted":true},"outputs":[],"source":["pipeline = pipeline.fit(data)\n","preds = pipeline.transform(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:03:02.980004Z","iopub.status.busy":"2023-02-15T14:03:02.975860Z","iopub.status.idle":"2023-02-15T14:03:03.349016Z","shell.execute_reply":"2023-02-15T14:03:03.347699Z","shell.execute_reply.started":"2023-02-15T14:03:02.979918Z"},"trusted":true},"outputs":[],"source":["preds.toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T14:16:35.486823Z","iopub.status.busy":"2023-02-15T14:16:35.485468Z","iopub.status.idle":"2023-02-15T14:16:36.318983Z","shell.execute_reply":"2023-02-15T14:16:36.317920Z","shell.execute_reply.started":"2023-02-15T14:16:35.486764Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","df = preds.toPandas()\n","pca = PCA(n_components=2)\n","df_pca = pd.DataFrame(pca.fit_transform(df[cols]))\n","df_pca['preds'] = preds.toPandas()['prediction']\n","df[0] = df_pca[0]\n","df[1] = df_pca[1]\n","df['preds'] = df_pca['preds']\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.set()\n","plt.figure(figsize = (10, 7))\n","plt.title('Principal component analysis (PCA) means df VS Clusters', fontdict={'fontsize': 25})\n","sns.scatterplot(data=df, x=0, y=1, hue=\"preds\", legend=\"full\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
