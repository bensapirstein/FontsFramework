{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import defcon\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from data_utils import parse_list, glyph_to_img,\\\n",
    "    glyph_stats, glyph_to_svg_path, normalize_glyph,\\\n",
    "    transform_svg, svg_format\n",
    "\n",
    "df = pd.read_csv(\"ufo_data.csv\", converters={\"subsets\": parse_list, \"variants\":ast.literal_eval})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"GenerativeFontsDataset\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the glyph data for each variant\n",
    "glyph_data = {}\n",
    "\n",
    "# Initialize an empty list to store the variant data\n",
    "variant_data = []\n",
    "\n",
    "M = 3\n",
    "\n",
    "# Iterate through each font family and variant in the font_dataset DataFrame\n",
    "for _, row in tqdm(df[:M].iterrows(), total=M, desc=\"Processing Variants...\"):\n",
    "    family = row['family']\n",
    "    variants = row['variants']\n",
    "\n",
    "    for variant, ufo_file_path in variants.items():\n",
    "        # Open the UFO file for the font\n",
    "        font = defcon.Font(ufo_file_path)\n",
    "\n",
    "        variant_info = {\n",
    "            'ascender' : font.info.ascender,\n",
    "            'capHeight' : font.info.capHeight,\n",
    "            'descender' : font.info.descender,\n",
    "            'italicAngle' : font.info.italicAngle,\n",
    "            'xHeight' : font.info.xHeight,\n",
    "            'unitsPerEm' : font.info.unitsPerEm,\n",
    "        }\n",
    "\n",
    "        # Add the variant data to the list\n",
    "        variant_data.append({'family': family, 'variant': variant, **variant_info})\n",
    "\n",
    "        # Initialize an empty list to store the glyph data for the variant\n",
    "        glyph_data[(family, variant)] = []\n",
    "\n",
    "        # Iterate through each glyph in the font\n",
    "        for glyph_name in font.keys():\n",
    "            # Get the glyph object for the glyph\n",
    "            glyph = font[glyph_name]\n",
    "\n",
    "            meanX, meanY, stddevX, stddevY = glyph_stats(glyph)\n",
    "\n",
    "            # Split the bounds tuple into separate fields\n",
    "            bl_x, bl_y, tr_x, tr_y = glyph.bounds if glyph.bounds else [None]*4\n",
    "\n",
    "            # Create a dictionary to store the glyph data\n",
    "            glyph_dict = {\n",
    "                'glyph_name': glyph_name,\n",
    "                'svg': glyph_to_svg_path(glyph),\n",
    "                'advance': glyph.width,\n",
    "                'unicode' : glyph.unicode,\n",
    "                'meanX' : meanX,\n",
    "                'meanY' : meanY,\n",
    "                'stddevX' : stddevX,\n",
    "                'stddevY' : stddevY,\n",
    "                'area' : glyph.area,\n",
    "                'bottomLeftX' : bl_x,\n",
    "                'bottomLeftY' : bl_y,\n",
    "                'topRightX' : tr_x,\n",
    "                'topRightY' : tr_y,\n",
    "            }\n",
    "            # Add the glyph data to the list\n",
    "            glyph_data[(family, variant)].append(glyph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the variant information\n",
    "variants_df = spark.createDataFrame(variant_data)\n",
    "\n",
    "# Create a DataFrame for the glyph information\n",
    "glyphs_df_spark = spark.createDataFrame([{'family': family, 'variant': variant, 'glyphs': glyphs} for (family, variant), glyphs in glyph_data.items()])\n",
    "\n",
    "# Join the variants_df DataFrame with the glyphs_df_spark DataFrame on the 'variant' column\n",
    "joined_df = variants_df.join(glyphs_df_spark, on=['family', 'variant'])\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "joined_df.show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the glyphs_df_spark dataframe to create a list of rows\n",
    "glyph_rows = glyphs_df_spark.rdd.flatMap(lambda x: [{**glyph, **{'family': x['family'], 'variant': x['variant']}} for glyph in x['glyphs']]).collect()\n",
    "\n",
    "# Create a dataframe from the glyph rows\n",
    "glyphs_df = spark.createDataFrame(glyph_rows)\n",
    "\n",
    "# Show the resulting dataframe\n",
    "glyphs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "aggf= {'advance': 'avg','meanX' : 'avg','meanY' : 'avg','stddevX' : 'avg','stddevY' : 'avg','area' : 'avg','bottomLeftX' : 'avg','bottomLeftY' : 'avg','topRightX' : 'avg','topRightY' : 'avg'}\n",
    "mean_df= glyphs_df.groupBy('family','variant').agg(aggf)\n",
    "pandasMeans_DF = mean_df.toPandas()\n",
    "pandasMeans_DF.to_csv('means_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
